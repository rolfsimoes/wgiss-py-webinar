{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Web Service of Time Series of Earth Observation Data\n",
    "\n",
    "## Context: The e-sensing project\n",
    "\n",
    "The e-sensing project is about developing new ways to extract information on land use and land cover change from big Earth Observation data sets. We address the following scientific question: \n",
    "\n",
    "***How can we use e-science methods and techniques to improve the extraction of land use and land cover change information from big Earth Observation data sets in an open and reproducible way?*** \n",
    "\n",
    "To answer this, our project is building a new generation of knowledge platform for handling big geospatial data. We're conceiving, building, and deploying a new type of knowledge platform for accessing, processing and analyzing big Earth Observation data.\n",
    "\n",
    "We assume that decades of satellite images can be effectively organized into a data structure which can be efficiently queried and processed using the array data model. \n",
    "\n",
    "<img src=\"img/datacube.png\" alt=\"A data cube of satellite images is as an array\" title=\"data cube\" height=\"300\" width=\"400\" />\n",
    "\n",
    "Our approach is to put data and analysis together to help scientists to do larger, longer, and faster research on land use and land cover change.\n",
    "\n",
    "<img src=\"img/architecture.png\" alt=\"e-sensing project's architecture \" title=\"e-sensing architecture\" height=\"300\" width=\"400\" />\n",
    "\n",
    "The \"e-sensing\" project is supported by __[FAPESP](http://bv.fapesp.br/pt/auxilios/89598/e-sensing-analise-de-grandes-volumes-de-dados-de-observacao-da-terra-para-informacao-de-mudancas-de/)__, under the  __[e-science program](http://www.fapesp.br/8436)__ .\n",
    "\n",
    "For additional information, please visits us at:\n",
    "\n",
    "- our  __[official page](http://esensing.org/)__ \n",
    "- our code repository at __[github](https://github.com/e-sensing/)__\n",
    "- our project at __[research gate](https://www.researchgate.net/project/e-sensing-big-earth-observation-data-analytics-for-land-use-and-land-cover-change-information-wwwesensingorg)__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Time Series Service\n",
    "\n",
    "The Web Time Series Service (WTSS) is a lightweight web service for handling time series data from remote sensing imagery. It exposes three operations:\n",
    "- ```list_coverages```: get the list of available coverages.\n",
    "- ```describe_coverage```: get metadata about a specific coverage.\n",
    "- ```time_series```: get a time series for a given location and time interval.\n",
    "\n",
    "WTSS is developed and maintained by the National Institute for Space Research of Brazil __[INPE](http://www.inpe.br/)__, where we have a WTSS instance running.\n",
    "\n",
    "For additional details such as the source code and the WTSS clients for Python, R, Javascript and C++ go to the __[WTSS repository](https://github.com/e-sensing/tws/tree/master/src/tws/wtss)__. \n",
    "\n",
    "If you are interested on setting your own WTSS, you can contact us through the __[e-sensing](http://esensing.org/)__ links provided above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTSS for Python\n",
    "\n",
    "The __[python client](https://github.com/e-sensing/wtss.py)__ for WTSS enables users to retrieve time series of Earth observation data for specific locations. Using a few lines of code, you can retrieve data from Earth observation.\n",
    " WTSS easily integrates with Python analysis libraries such as __[numpy](http://www.numpy.org)__, __[scipy](https://www.scipy.org)__, __[pandas](http://pandas.pydata.org)__ and __[matplotlib](https://matplotlib.org)__.\n",
    "\n",
    "### WTSS: List coverages\n",
    "\n",
    "This operation gets a list of the data sets hosted in the WTSS. In the example below, we import the WTSS module and then create a WTSS object to query and print the list of available data sets in the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wtss import wtss\n",
    "\n",
    "# WTSS python client: Access to data & metadata\n",
    "w = wtss(\"http://www.dpi.inpe.br/tws\")\n",
    "\n",
    "# print the available data sets\n",
    "cv_list = w.list_coverages()\n",
    "for cv_name in cv_list[\"coverages\"]:\n",
    "    print(cv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTSS: Describe coverage\n",
    "\n",
    "This operations enables users to explore the details of a data set in the WTSS. Below, we ask WTSS for the details of a coverage. Then we format and print the WTSS's reponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore a WTSS data set\n",
    "cv_scheme = w.describe_coverage(\"mod13q1_512\")\n",
    "\n",
    "# format response\n",
    "print(\"ARRAY: {}\".format(cv_scheme[\"name\"]))\n",
    "print(\"\\nDESCRIPTION:\\n\" + str(cv_scheme['description']) + \" - \" + str(cv_scheme['detail']))\n",
    "print(\"\\nDIMENSIONS:{}\\n\".format(cv_scheme['dimensions']))\n",
    "print(\"\\nSPATIAL EXTENT:{}\\n\".format(cv_scheme['spatial_extent']))\n",
    "print(\"\\nCRS:{}\\n\".format(cv_scheme['crs']['wkt']))\n",
    "print(\"\\nTIMELINE:\\nFirst five: {}...\\nLast  five: ...{}\".format(cv_scheme['timeline'][0:5], cv_scheme['timeline'][-5:]))\n",
    "\n",
    "print(\"\\nATTRIBUTES:\")\n",
    "\n",
    "for att in cv_scheme['attributes']:\n",
    "    print(\"{}: {}. Type: {}\".format(att['name'], att['description'], att['datatype']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WTSS: Time series\n",
    "\n",
    "This operation retrieves a time series of the provided point. Here, we ask WTSS for some vegetation indexes, then we create *pandas* series out of them, and finally we put the series together into a *pandas* data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "latitude = -12.0\n",
    "longitude = -54.0\n",
    "\n",
    "# get time series of a point\n",
    "ts = w.time_series(\"mod13q1_512\", (\"ndvi\", \"evi\"), latitude, longitude)\n",
    "\n",
    "# build a data frame made of vegetation indexes\n",
    "ndvi = pd.Series(ts[\"ndvi\"], index = ts.timeline)/10000\n",
    "evi  = pd.Series(ts[\"evi\"],  index = ts.timeline)/10000\n",
    "\n",
    "vidf = pd.DataFrame({'ndvi': ndvi, 'evi': evi})\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the choosen location over a map of MODIS NDVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsmap import *\n",
    "\n",
    "location = {'lat': latitude, 'lon': longitude}\n",
    "\n",
    "map = createTSMap(location, vidf)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTSS and Python Data Analysis Library\n",
    "\n",
    "### Data Visualization\n",
    "\n",
    "Python provides tools for scientific data visualization. Below, we take advantage of the integration between *pandas* and *matplotlib* in order to plot our vegetation indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from cycler import cycler\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Updating default matplotlib colors\n",
    "colors = cycler(u'color', [u'#74c476',u'#6baed6',u'#d62728', u'#ff7f0e', u'#756bb1'])\n",
    "matplotlib.rcParams['axes.prop_cycle'] = colors\n",
    "\n",
    "# Time series visualization\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line fitting\n",
    "\n",
    "A simple way to reveal coarse trends in time series is to adjust a straight line through the data. In the code below, we have a function to fit lines which we use in our time series. Then we plot the vegetation indexes along the adjusted lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# fit a line to a time series\n",
    "def fitline(vi):\n",
    "    \"\"\"!\n",
    "    Fit a line to a time series.\n",
    "    @param vi pandas.Series: A time series\n",
    "    @return   Return a numpy.ndarray with the values of the fitted line for each element in vi.\n",
    "    \"\"\"\n",
    "    vi = pd.Series(vi.values, index = range(len(vi.values)))                       # re-build the series\n",
    "    obid = pd.Series(range(len(vi.values)), index = range(len(vi.values)))         # add an index to the series\n",
    "    sl, it, r, p, sde = stats.linregress(x = range(len(vi.values)), y = vi.values) # fit the line\n",
    "    lmdf = pd.DataFrame({'obid': obid, 'vi': vi})                                  # build a data frame\n",
    "    lmdf['vi_lm'] = lmdf['obid'] * sl + it                                         # compute the line's points\n",
    "    return(lmdf['vi_lm'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a line to the vegetation indexes\n",
    "vidf['ndvi_lm'] = fitline(vidf['ndvi'])\n",
    "vidf['evi_lm'] = fitline(vidf['evi'])\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_lm'].plot()\n",
    "vidf['evi_lm'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier decomposition\n",
    "\n",
    "Fourier series analysis allow us to decompose time series into a sum of waves represented by periodic functions. These functions have properties such as amplitude, wavelength, and frequency. In time series analysis, it is accepted that high frequencies are associated with noise. Therefore, in order to diminish noise we need to remove high frequencies from our time series. \n",
    "\n",
    "In the example below, the Fourier filter function removes any trend in the data by fitting a line, then it computes the Fast Fourier Transform (FFT), then it removes the frequencies higher than a given threshold, and finally computes the Inverse FFT to re-build a smoother time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fourier decomposition\n",
    "def fourierfilter(vi, fq_keep):\n",
    "    \"\"\"!\n",
    "    Filter a time series using Fourier decomposition.\n",
    "    @param vi      pandas.Series: A time series\n",
    "    @param fq_keep int: The number of low frequencies to keep\n",
    "    @return        Return a numpy.ndarray with filtered values for each element in vi.\n",
    "    \"\"\"\n",
    "    vi = pd.Series(vi.values, index = range(len(vi.values)))               # re-build the series\n",
    "    fdf = pd.DataFrame({'vi': vi})\n",
    "    ## de-trend the time series by fitting a trend line\n",
    "    fdf['vi_lm'] = fitline(fdf['vi'])\n",
    "    fdf['residual'] = fdf['vi'] - fdf['vi_lm']\n",
    "    # compute the discrete Fourier Transform\n",
    "    vi_fft = np.fft.fft(fdf['residual'].values).real\n",
    "    # remove the frequencies from index fq_keep to the last one\n",
    "    vi_fft[fq_keep:] = 0\n",
    "    # compute the inverse discrete Fourier Transform\n",
    "    vi_ifft = np.fft.ifft(vi_fft).real\n",
    "    # add the residuals back\n",
    "    return(vi_ifft + fdf['vi_lm'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the vi\n",
    "vidf['ndvi_ff'] = fourierfilter(vidf['ndvi'], 25)\n",
    "vidf['evi_ff'] = fourierfilter(vidf['evi'], 45)\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_ff'].plot()\n",
    "vidf['evi_ff'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whittaker smoothing filter\n",
    "\n",
    "Whitakker filter is obtained by a linear combination of time series nearest neighbors points measures [[Eilers2003]](#references). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a function that implements a Whittaker smoother in Python. \n",
    "# Source: https://gist.github.com/zmeri/3c43d3b98a00c02f81c2ab1aaacc3a49\n",
    "\n",
    "import scipy\n",
    "import scipy.sparse.linalg\n",
    "\n",
    "\n",
    "def whittaker_filter(y, lmda=1.0):\n",
    "    m = len(y)\n",
    "    E = scipy.sparse.identity(m)\n",
    "    d1 = -1 * np.ones((m), dtype='d')\n",
    "    d2 = 3 * np.ones((m), dtype='d')\n",
    "    d3 = -3 * np.ones((m), dtype='d')\n",
    "    d4 = np.ones((m), dtype='d')\n",
    "    D = scipy.sparse.diags([d1, d2, d3, d4], [0, 1, 2, 3], shape=(m - 3, m), format=\"csr\")\n",
    "    z = scipy.sparse.linalg.cg(E + lmda * (D.transpose()).dot(D), y)\n",
    "    return z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the vi\n",
    "vidf['ndvi_wf'] = pd.Series(whittaker_filter(ndvi), index = ts.timeline)\n",
    "vidf['evi_wf']  = pd.Series(whittaker_filter(evi), index = ts.timeline)\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_wf'].plot()\n",
    "vidf['evi_wf'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman filter\n",
    "\n",
    "The Kalman filter aims to separate time series from noise. It is an iterative algorithm on which the outputs of one iteration are the inputs for the next one. In this way, the filter successively improves its estimations of the true value of a time series. \n",
    "\n",
    "In the example below, we estimate the initial parameters for the filter from the time series itself. Then we compute the Kalman filter and plot the smoothed vegetation indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kalman filter\n",
    "def kalmanfilter(vi, e_mea = None, est_0 = None, e_est_0 = None):\n",
    "    \"\"\"!\n",
    "    Filter a time series using the Kalman filter.\n",
    "    @param vi      pandas.Series: A time series made of measurements\n",
    "    @param e_mea   int: The error in the measurements\n",
    "    @param est_0   int: The estimate of the first measurement\n",
    "    @param e_est_0 int: The initial error in the estimate\n",
    "    @return        Return a numpy.ndarray with filtered values for each element in vi.\n",
    "    \"\"\"\n",
    "    est   = np.zeros(len(vi)) # estimation\n",
    "    e_est = np.zeros(len(vi)) # error in estimation\n",
    "    kg    = np.zeros(len(vi)) # Kalman gain\n",
    "    # deal with missing values\n",
    "    if est_0 is None:\n",
    "        est[0]   = vi.mean()\n",
    "    else:\n",
    "        est[0]   = est_0\n",
    "    if e_mea is None:\n",
    "        e_mea = vi.std()\n",
    "    if e_est_0 is None:\n",
    "        e_est[0] = 3 * vi.std()\n",
    "    else:\n",
    "        e_est[0] = e_est_0\n",
    "    # do the filtering\n",
    "    kg[0]    = None\n",
    "    for i in range(1, len(vi)):\n",
    "        kg[i] = e_est[i - 1]/(e_est[i - 1] + e_mea)    # compute the Kalman gain\n",
    "        m = vi[i - 1]\n",
    "        if(np.isnan(m)):\n",
    "            m = est[i - 1]                             # use the estimation when a measurement is missing\n",
    "        est[i] = est[i - 1] + kg[i] * (m - est[i - 1]) # compute the new estimation\n",
    "        e_est[i] = (1 - kg[i]) * e_est[i - 1]\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the vi\n",
    "vidf['ndvi_kf'] = pd.Series(kalmanfilter(ndvi), index = ts.timeline)\n",
    "vidf['evi_kf']  = pd.Series(kalmanfilter(evi), index = ts.timeline)\n",
    "\n",
    "# plot\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "ax.plot()\n",
    "vidf['ndvi'].plot()\n",
    "vidf['evi'].plot()\n",
    "vidf['ndvi_kf'].plot()\n",
    "vidf['evi_kf'].plot()\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()\n",
    "vidf[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Time Warping\n",
    "\n",
    "Dynamic Time Warping (DTW) is a shape-based distance function that minimizes distances between two time series by warping time dimension. DTW allows time series comparisons of different length. Here, we use DTW distance in nearest pattern classifier to provide an overview of its versatility. \n",
    "\n",
    "Our experiment consists of 10 ground truth samples of labels `Forest` (5) and `Cerrado` (5), taken from Brazilian state of Mato Grosso. We provide the respective prototypes for each land cover class, obtained elsewere (Ref). We applied DTW distance function on all pairs of both samples and patterns data set to compose a dissimilarity matrix from which we extracted the predictors land cover classes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DTW and classification functions\n",
    "from dtw import *\n",
    "\n",
    "# functions to get time series from wtss and plotting time series samples \n",
    "from tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above modules implements functions that simplifies our next code.\n",
    "You can read them in following links: \n",
    "- [dtw.py](./dtw.py)\n",
    "- [tools.py](./tools.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open samples from file\n",
    "samples = pd.read_csv(\"examples/samples.csv\")\n",
    "\n",
    "samples[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtss_get_time_series function is implemented in 'tools.py'\n",
    "samples_ts = wtss_get_time_series(samples)\n",
    "\n",
    "# rescale vegetation index to -1.0~1.0 range\n",
    "samples_ts[\"ndvi\"] *= 0.0001\n",
    "samples_ts[\"evi\"] *= 0.0001\n",
    "\n",
    "samples_ts[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot samples time series\n",
    "plot_time_series(samples_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open patterns from file\n",
    "# these patterns were extracted using GAM on a larger data set \n",
    "patterns_ts = pd.read_json(\"examples/patterns.json\", orient='records')\n",
    "# update timeline type from str to datetime\n",
    "patterns_ts[\"timeline\"] = pd.to_datetime(patterns_ts[\"timeline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot patterns time series\n",
    "plot_time_series(patterns_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = classifier_1nn(patterns_ts, samples_ts)\n",
    "\n",
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let see what happened with sample #3\n",
    "plot_time_series(pd.concat([samples_ts[samples_ts[\"id\"].isin([3])], patterns_ts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "We introduced the Web Time Series Service (WTSS), a light weight Web Service of time series of Earth observation data. Through examples and code, we show how the WTSS is used and integrated with Python's scientific libraries such as NumPy, SciPy and Pandas. We demonstrated how WTSS fits into the analytic work flow of Earth Observation Scientists by using it to obtain and filter data.\n",
    "\n",
    "What are the constraints of WTSS?\n",
    "- So far, our WTSS implementation only provides data from MODIS __[MOD13Q1](https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mod13q1)__\n",
    "- The WTSS interface is still simple, we need to extend the service in order to serve complex applications\n",
    "\n",
    "What is missing?\n",
    "- Today, in terms of Map Algebra, WTSS enables local operations. We need to extend it to focal, zonal and global operations.\n",
    "- WTSS is about time series analysis. But we still need to see cubes of satellite data as images. In other words, we need the equivalent of Web Mapping Server, Web Feature Service, and Web Coverage Server for big Earth observation data.\n",
    "- Our Array database cluster (SciDB) is slow for retrieving images and it does not have native support for the spatio-temporal metadata associated with Earth observation imagery\n",
    "\n",
    "Finally, we would like to invite you to explore some results of the **e-sensing** project by clicking __[here](http://terrabrasilis.info/composer/E-SENSING)__. We are working on new features of WTSS and also a new Web Service for processing large amounts of Earth observation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "<a id=\"references\"></a>\n",
    "[Eilers2003]: Paul H. C. Eilers. \"A Perfect Smoother\". Analytical Chemistry, 2003, 75 (14), pp 3631â€“3636."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [geospatial]",
   "language": "python",
   "name": "geospatial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
